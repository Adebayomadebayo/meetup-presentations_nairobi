---
title: <center><strong> Working with databases in R </strong></center>
author: <center><strong> Christopher Maronga - R Programmer </strong></center>
date: <center><strong> `r format(Sys.time(), '%d %B, %Y')` </strong></center>
output: 
  html_document:
    keep_md: yes
    number_sections: yes
    theme: united
    toc: yes
    toc_depth: 4
    toc_float:
      collapsed: yes
      smooth_scroll: yes
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = F, message = F,
                      echo = T, 
                      dpi = 180, 
                      fig.width = 12, 
                      fig.height = 8,
                      results = "asis")
```


# Loading packages

```{r packages}
library(DBI)  # R database interface
library(odbc)  # connection to odbc compatible database
library(RSQLite) # Backed driver for SQLite
library(RMySQL) # Backed driver for MySQL
library(tidyverse) # dplyr verbs and more
library(redcapAPI) # connecting to REDCap database
library(here)  # manage working directories
library(DT)
```


## Available drivers for `odbc`

```{r}
odbcListDrivers()[[1]] %>% unique()
```


# Connecting to `MySQL` database

You can connect to `MySQL` in two ways:-

## Using an `odbc` driver


```{r}
# using appropriate odbc driver
# Not appropriate for serverless databases such as SQLite; first letters of all arguments are uppercase

nai_con1 <- dbConnect(odbc(),
                      Driver = Sys.getenv("driver"),
                      Server = Sys.getenv("server"),
                      Uid = Sys.getenv("uid"),
                      Database = Sys.getenv("database") ,
                      Pwd = Sys.getenv("pwd"))


dbListTables(nai_con1)

```


## `DBI` compliant R package

Provide `DBI` compliant back-end for connecting to RDBMS. These include `RMySQL`, `RSQLite`, `ROracle`, `RPostgreSQL` etc.

```{r}
# use of DBI compliant R packages

nai_con2 <- dbConnect(MySQL(),
                      host = "localhost",
                      dbname = "naidemostudy",
                      user = "root",
                      password = "root@2021Train!")

dbListTables(nai_con2)

# world
world_con <- dbConnect(MySQL(),
                       host = "localhost",
                       dbname = "world",
                       user = "root",
                       password = "root@2021Train!")

dbListTables(world_con)
```


# Connecting to `SQLite` database

Light-weight and serverless database

```{r}
# need to supply the backend driver and dbname/location .db file

nyc_con1 <- dbConnect(SQLite(),
                      dbname = here("SQLite_databases", "nyc_flights.db"))

dbListTables(nyc_con1)

```



# Exploring the `DBI` functions

## List tables in a database
```{r}
# List tables in a database

dbListTables(world_con)

```

## List field names in tables
```{r}
# List field names of a particular database table
dbListFields(nai_con2, "tbl_baseline")

```


## Execute a `SQL` query
```{r}
# Execute a query in a database

worl_res <- dbSendQuery(world_con, "SELECT * FROM city")


```

## Fetch results of a query
```{r}
# Fetch results from a previously executed query
# returns a data frame 

dframe <- dbFetch(worl_res)

dbClearResult(worl_res)
```


## Execute and fetch query results
```{r}
# Execute/send query and fetch/retrieve results at ago
# returns a data frame

dframe2 <- dbGetQuery(world_con, "SELECT * FROM city")

# JOIN
world_data <- dbGetQuery(world_con, "SELECT * FROM city AS c
                         JOIN countrylanguage As con ON c.CountryCode = con.CountryCode")


```


## Read a database table
```{r}
# Read tables of the database as dataframes dbReadTable
# Basically skip the SELECT * ----

dframe3 <- dbReadTable(nai_con1, "tbl_disch") # SELECT * FROM tbl_dish


```


## Connection metadata
```{r}
# Metadata about the connection
dbGetInfo(nai_con1)


```


# Using `dplyr` functions

## `tbl` function
```{r}

tbl(nai_con2, "tbl_baseline") %>% 
  select(subjid, agemonth, base_muac) %>% 

```


## `show_query` function

Getting to see/view the SQL code generated by tidyverse workflow
```{r}

tbl(nai_con2, "tbl_baseline") %>% 
  select(subjid, agemonth, base_muac) %>% show_query()

tbl(nai_con2, "tbl_baseline") %>% 
  filter(agemonth >= 10) %>% show_query()


```


## `collect` function


# Closing database connection

```{r}
nai_dframe1 <- tbl(nai_con2, "tbl_baseline") %>% 
  select(subjid, agemonth, base_muac) %>% collect()

city_dframe <- tbl(world_con, "city") %>% collect() # dbReadTable()


# JOIN

tbl(nai_con1, "tbl_baseline") %>% 
  left_join(tbl(nai_con1, "tbl_disch"),
            by = "subjid") %>% show_query()

base_dish <- tbl(nai_con1, "tbl_baseline") %>% 
  left_join(tbl(nai_con1, "tbl_disch"),
            by = "subjid") %>% collect()


```


# Connecting via `sql` chunk

````{sql connection = "nai_con1", output.var = "nain_dframe3"}

SELECT * FROM `tbl_baseline`

```



# Connecting to `REDCap` database


```{r}
# To create a connection, you need to supply
  # 1. redcap url
  # 2. API token
redcap_con <- redcapConnection(url = "https://uat.chainnetwork.org/redcap/api/",
                               token = "76B2DF219CCFBC048E8661AD64CB7205")

```


## List REDCap events

```{r}
events <- exportEvents(redcap_con)

```


## List database instruments

```{r}
instruments <- exportInstruments(redcap_con)

```



## Database metadata

```{r}
meta_info <- exportMetaData(redcap_con)

```


## Export records

Can be achieved in 3 ways

### Export all records

Suitable for small-sized databases

```{r}
all_records <- exportRecords(redcap_con)
```

### Export by event

Useful for otherwise very large databases to speed up things

```{r}

?exportRecords

event_one <- exportRecords(
  rcon,
  factors = TRUE,
  fields = NULL,
  forms = NULL,
  records = NULL,
  events = "name_of_event_here",
  labels = TRUE,
  dates = TRUE,
  survey = TRUE,
  dag = TRUE,
  checkboxLabels = FALSE)

# two or more events

events_data <- event_one <- exportRecords(
  rcon,
  factors = TRUE,
  fields = NULL,
  forms = NULL,
  records = NULL,
  events = c("event1", "event2"),
  labels = TRUE,
  dates = TRUE,
  survey = TRUE,
  dag = TRUE,
  checkboxLabels = FALSE)

```


### Export by instrument

Exporting an instrument at a time. This takes the form of the above (extracting by event), by suppling a vector of instruments you want to export via `forms` argument.

```{r}
?exportInstruments

instrument_one <- events_data <- event_one <- exportRecords(
  rcon,
  factors = TRUE,
  fields = NULL,
  forms = "name_of_instrument_here",
  records = NULL,
  events = c("event1", "event2"),
  labels = TRUE,
  dates = TRUE,
  survey = TRUE,
  dag = TRUE,
  checkboxLabels = FALSE)


# more than one instrument
instrument_data <- events_data <- event_one <- exportRecords(
  rcon,
  factors = TRUE,
  fields = NULL,
  forms = c("instrument1", "instrument2"),
  records = NULL,
  events = c("event1", "event2"),
  labels = TRUE,
  dates = TRUE,
  survey = TRUE,
  dag = TRUE,
  checkboxLabels = FALSE)


```


## Export users
View and manage users accessing your database

```{r}
users <- exportUsers(redcap_con)
```


# API security

```{r}

file.edit("~/.Renviron")

```

 
Create variables in the `.Renvrion` and access them using `Sys.getenv`.
This way, you get to keep your API tokes and password to databases a secret
```{r}
nai_con1 <- dbConnect(odbc(),
                      Driver = Sys.getenv("driver"),
                      Server = Sys.getenv("server"),
                      Uid = Sys.getenv("uid"),
                      Database = Sys.getenv("database") ,
                      Pwd = Sys.getenv("pwd"))
```
















